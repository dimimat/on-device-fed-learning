{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mid Training Drop Out Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import re\n",
    "from statistics import mean, stdev\n",
    "statistics_path = os.path.abspath(\"../\")\n",
    "sys.path.append(statistics_path)\n",
    "import stats_utils\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_exp_statistics = \"/Users/admin/Desktop/thesis/dataset/metrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_exp_images = \"/Users/admin/Desktop/thesis_writing/experiment_images/network_experiments/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute Accuracy Plot for every dataset in a single diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"exp_8_0_1\"\n",
    "zero_missing = stats_utils.parse_experiments_statistics_to_df(path_to_exp_statistics, exp_name, csv_filename=\"logs.csv\")\n",
    "\n",
    "exp_name = \"exp_8_1_2\"\n",
    "one_missing = stats_utils.parse_experiments_statistics_to_df(path_to_exp_statistics, exp_name, csv_filename=\"logs.csv\")\n",
    "\n",
    "exp_name = \"exp_8_2_1\"\n",
    "two_missing = stats_utils.parse_experiments_statistics_to_df(path_to_exp_statistics, exp_name, csv_filename=\"logs.csv\")\n",
    "\n",
    "exp_name = \"exp_8_3_1\"\n",
    "three_missing = stats_utils.parse_experiments_statistics_to_df(path_to_exp_statistics, exp_name, csv_filename=\"logs.csv\")\n",
    "\n",
    "exp_name = \"exp_8_4_1\"\n",
    "four_missing = stats_utils.parse_experiments_statistics_to_df(path_to_exp_statistics, exp_name, csv_filename=\"logs.csv\")\n",
    "\n",
    "dfs = [one_missing, two_missing, three_missing, four_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss_from_dfs(\n",
    "    dfs,\n",
    "    get_accuracy_loss_values,\n",
    "    path_to_exp_images,\n",
    "    should_save=False,\n",
    "    filename=\"accuracies_for_every_dataset\",\n",
    "    label_names=None,\n",
    "    title=\"\"\n",
    "):\n",
    "    accs = {}\n",
    "    losses = {}\n",
    "\n",
    "    # 1) Extract accuracy & loss per dataset\n",
    "    for i, df in enumerate(dfs):\n",
    "        label = label_names[i]\n",
    "        first_client = ast.literal_eval(df[\"devices_names\"][0])[0]\n",
    "        acc, loss = get_accuracy_loss_values(df, first_client)\n",
    "        accs[label] = acc\n",
    "        losses[label] = loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, first_client_name):\n",
    "    acc, _ = stats_utils.get_accuracy_loss_values_for_dfs(df, first_client_name)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"mid_training_drop_out_test\"\n",
    "title = \"Impact of Mid-Training Client Dropout\"\n",
    "label_names = [\"All Clients Participating\", \"1 Client Dropped\", \"2 Clients Dropped\", \\\n",
    "               \"3 Clients Dropped\", \"4 Clients Dropped\"]\n",
    "first_client_name = [\"Xiaomi M2006C3MNG\", \"samsung SM-G975F\", \"samsung SM-J730F\", \"samsung SM-G975F\", \\\n",
    "                    \"samsung SM-G975F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = {}\n",
    "# zero clients missing\n",
    "acc = get_accuracy(zero_missing, first_client_name[0])\n",
    "accs[label_names[0]] = acc\n",
    "\n",
    "# one client missing\n",
    "acc = get_accuracy(one_missing, first_client_name[1])\n",
    "accs[label_names[1]] = acc\n",
    "\n",
    "# two clients missing\n",
    "acc = get_accuracy(two_missing, first_client_name[2])\n",
    "accs[label_names[2]] = acc\n",
    "\n",
    "# three clients missing\n",
    "acc = get_accuracy(three_missing, first_client_name[3])\n",
    "accs[label_names[3]] = acc\n",
    "\n",
    "# four client missing\n",
    "acc = get_accuracy(four_missing, first_client_name[4])\n",
    "accs[label_names[4]] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Clients Participating\n",
      "1 Client Dropped\n",
      "2 Clients Dropped\n",
      "3 Clients Dropped\n",
      "4 Clients Dropped\n"
     ]
    }
   ],
   "source": [
    "should_save = True\n",
    "n_rounds = len(next(iter(accs.values())))\n",
    "rounds = list(range(1, n_rounds + 1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for label, values in accs.items():\n",
    "    print(label)\n",
    "    ax.plot(rounds, values, label=label)\n",
    "\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_xticks(rounds)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if not should_save:\n",
    "    plt.show()\n",
    "else:\n",
    "    path_to_file = os.path.join(path_to_exp_images, filename + \".png\")\n",
    "    fig.savefig(path_to_file, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
